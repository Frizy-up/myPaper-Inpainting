\relax 
\citation{Efros1999::Texture,Lu2010::Novel}
\citation{Rane2002::Wavelet,Rane2003:IToIP:Structure}
\citation{Bertalmio2000::Image,Shih2005::Digital}
\citation{Geiger2012::Are}
\citation{Efros1999::Texture,Drori2003::Fragment,Wilczkowiak2005::Hole,Barnes2009:AToG:PatchMatch:}
\citation{Drori2003::Fragment}
\citation{Wilczkowiak2005::Hole}
\citation{Barnes2009:AToG:PatchMatch:}
\citation{Barnes2009:AToG:PatchMatch:}
\citation{Hays2007::Scene}
\citation{Hinton2006:s:Reducing,Bengio:Co:Learning}
\citation{Vincent2008::Extracting}
\citation{Goodfellow2014::Generative}
\citation{Radford2016::Unsupervised}
\citation{Pathak2016::Context}
\citation{Li2017::Generative}
\citation{Mirza2014:CS:Conditional}
\citation{Isola2017::Image}
\citation{Ronneberger2015::U}
\citation{Li2016::Precomputed}
\@writefile{toc}{\contentsline {section}{\numberline {I}Introduction}{1}}
\citation{Jaderberg2015::Spatial}
\citation{Howard2017:apa:Mobilenets}
\citation{Zhang2017:apa:Shufflenet}
\citation{Ess2008::mobile}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces A vehicle equipped with four cameras(Cam0\texttildelow Cam3).}}{2}}
\newlabel{fig:VehicleWithFourCameras}{{1}{2}}
\newlabel{fig:methods_compare:input}{{2a}{2}}
\newlabel{sub@fig:methods_compare:input}{{(a)}{a}}
\newlabel{fig:methods_compare:condition}{{2b}{2}}
\newlabel{sub@fig:methods_compare:condition}{{(b)}{b}}
\newlabel{fig:methods_compare:target}{{2c}{2}}
\newlabel{sub@fig:methods_compare:target}{{(c)}{c}}
\newlabel{fig:methods_compare:patchMatch}{{2d}{2}}
\newlabel{sub@fig:methods_compare:patchMatch}{{(d)}{d}}
\newlabel{fig:methods_compare:Image2Image}{{2e}{2}}
\newlabel{sub@fig:methods_compare:Image2Image}{{(e)}{e}}
\newlabel{fig:methods_compare:ourMethod}{{2f}{2}}
\newlabel{sub@fig:methods_compare:ourMethod}{{(f)}{f}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Qualitative illustration of the different image inpainting methods. (a) Given an image with a missing region captured by left camera. (b) Given the same scene image captured by right camera. (c) The target of the left image inpainting. (d) PatchMatch method result. (e) Image-to-Image method result. (f) Our method result. }}{2}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {}}}{2}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {}}}{2}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {}}}{2}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces {}}}{2}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(e)}{\ignorespaces {}}}{2}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(f)}{\ignorespaces {}}}{2}}
\newlabel{fig:methods_compare:introduction}{{2}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {II}Proposed Algorithm}{2}}
\citation{Hinton2006:s:Reducing,Bengio:Co:Learning,Vincent2008::Extracting}
\citation{Pathak2016::Context}
\citation{Isola2017::Image}
\citation{Jaderberg2015::Spatial}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces The network architecture of our method.}}{3}}
\newlabel{fig:networkStruct}{{3}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {II-A}}Encoder-decoder}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {II-B}}Spatial Transform}{3}}
\citation{Howard2017:apa:Mobilenets}
\citation{Chollet2017::Xception:}
\citation{Xie2017::Aggregated}
\citation{Zhang2017:apa:Shufflenet}
\citation{Goodfellow2014::Generative}
\citation{Mirza2014:CS:Conditional}
\citation{BoesenLindboLarsen2015:apa:Autoencoding,Pathak2016::Context,Isola2017::Image}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces The spatial transform networks used in our method.}}{4}}
\newlabel{fig:stn}{{4}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Bilinear interpolation schematic.}}{4}}
\newlabel{bilinearInterpolation}{{5}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {II-C}}Group Convolution and Channel Shuffle}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Multi-view scene image inpainting based on conditional generative adversarial networks method diagram.}}{4}}
\newlabel{fig:CGAN}{{6}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {II-D}}Conditional Generative Adversarial Networks}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {II-E}}Joint Loss Function}{4}}
\citation{Ess2008::mobile}
\citation{Kingma2014:apa:Adam:}
\bibstyle{IEEEtran}
\bibdata{/mnt/hgfs/Downloads/refer-frizy/refer-frizy}
\bibcite{Efros1999::Texture}{1}
\newlabel{fig:experiment3:input}{{7a}{5}}
\newlabel{sub@fig:experiment3:input}{{(a)}{a}}
\newlabel{fig:experiment3:condition}{{7b}{5}}
\newlabel{sub@fig:experiment3:condition}{{(b)}{b}}
\newlabel{fig:experiment3:target}{{7c}{5}}
\newlabel{sub@fig:experiment3:target}{{(c)}{c}}
\newlabel{fig:experiment3:stn}{{7d}{5}}
\newlabel{sub@fig:experiment3:stn}{{(d)}{d}}
\newlabel{fig:experiment3:ours}{{7e}{5}}
\newlabel{sub@fig:experiment3:ours}{{(e)}{e}}
\newlabel{fig:experiment3:patchMatch}{{7f}{5}}
\newlabel{sub@fig:experiment3:patchMatch}{{(f)}{f}}
\newlabel{fig:experiment3:context-encoder}{{7g}{5}}
\newlabel{sub@fig:experiment3:context-encoder}{{(g)}{g}}
\newlabel{fig:experiment3:Image-to-Image}{{7h}{5}}
\newlabel{sub@fig:experiment3:Image-to-Image}{{(h)}{h}}
\newlabel{fig:experiment3:noShuffle}{{7i}{5}}
\newlabel{sub@fig:experiment3:noShuffle}{{(i)}{i}}
\newlabel{fig:experiment3:noSTN}{{7j}{5}}
\newlabel{sub@fig:experiment3:noSTN}{{(j)}{j}}
\newlabel{fig:experiment3:noGAN}{{7k}{5}}
\newlabel{sub@fig:experiment3:noGAN}{{(k)}{k}}
\newlabel{fig:experiment3:noL1}{{7l}{5}}
\newlabel{sub@fig:experiment3:noL1}{{(l)}{l}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Compare different image inpainting methods. (a) Input Left camera image. (b) Right camera image. (c) Target image. (d) The STN result. (e) Ours result. (f) Patch Match result. (g) Contexter-encoder result. (h) Image-to-Image result. (i) Ours(no shuffle) result. (j) Ours(no STN) result. (k) Ours(no GAN) result. (l) Ours(no L1) result.}}{5}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {}}}{5}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {}}}{5}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {}}}{5}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces {}}}{5}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(e)}{\ignorespaces {}}}{5}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(f)}{\ignorespaces {}}}{5}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(g)}{\ignorespaces {}}}{5}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(h)}{\ignorespaces {}}}{5}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(i)}{\ignorespaces {}}}{5}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(j)}{\ignorespaces {}}}{5}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(k)}{\ignorespaces {}}}{5}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(l)}{\ignorespaces {}}}{5}}
\newlabel{fig:experiment3}{{7}{5}}
\@writefile{toc}{\contentsline {section}{\numberline {III}Experiments}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-A}}Database Description}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-B}}Experimental Setup}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-C}}Experimental Results}{5}}
\@writefile{toc}{\contentsline {section}{\numberline {IV}Conclusion}{5}}
\@writefile{toc}{\contentsline {section}{Acknowledgment}{5}}
\bibcite{Lu2010::Novel}{2}
\bibcite{Rane2002::Wavelet}{3}
\bibcite{Rane2003:IToIP:Structure}{4}
\bibcite{Bertalmio2000::Image}{5}
\bibcite{Shih2005::Digital}{6}
\bibcite{Geiger2012::Are}{7}
\bibcite{Drori2003::Fragment}{8}
\bibcite{Wilczkowiak2005::Hole}{9}
\bibcite{Barnes2009:AToG:PatchMatch:}{10}
\newlabel{fig:experiment:input}{{8a}{6}}
\newlabel{sub@fig:experiment:input}{{(a)}{a}}
\newlabel{fig:experiment:condition}{{8b}{6}}
\newlabel{sub@fig:experiment:condition}{{(b)}{b}}
\newlabel{fig:experiment:target}{{8c}{6}}
\newlabel{sub@fig:experiment:target}{{(c)}{c}}
\newlabel{fig:experiment:stn}{{8d}{6}}
\newlabel{sub@fig:experiment:stn}{{(d)}{d}}
\newlabel{fig:experiment:ours}{{8e}{6}}
\newlabel{sub@fig:experiment:ours}{{(e)}{e}}
\newlabel{fig:experiment:patchMatch}{{8f}{6}}
\newlabel{sub@fig:experiment:patchMatch}{{(f)}{f}}
\newlabel{fig:experiment:context-encoder}{{8g}{6}}
\newlabel{sub@fig:experiment:context-encoder}{{(g)}{g}}
\newlabel{fig:experiment:Image-to-Image}{{8h}{6}}
\newlabel{sub@fig:experiment:Image-to-Image}{{(h)}{h}}
\newlabel{fig:experiment:noShuffle}{{8i}{6}}
\newlabel{sub@fig:experiment:noShuffle}{{(i)}{i}}
\newlabel{fig:experiment:noSTN}{{8j}{6}}
\newlabel{sub@fig:experiment:noSTN}{{(j)}{j}}
\newlabel{fig:experiment:noGAN}{{8k}{6}}
\newlabel{sub@fig:experiment:noGAN}{{(k)}{k}}
\newlabel{fig:experiment:noL1}{{8l}{6}}
\newlabel{sub@fig:experiment:noL1}{{(l)}{l}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Compare different image inpainting methods. (a) Input Left camera image. (b) Right camera image. (c) Target image. (d) The STN result. (e) Ours result. (f) Patch Match result. (g) Contexter-encoder result. (h) Image-to-Image result. (i) Ours(no shuffle) result. (j) Ours(no STN) result. (k) Ours(no GAN) result. (l) Ours(no L1) result.}}{6}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {}}}{6}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {}}}{6}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {}}}{6}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces {}}}{6}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(e)}{\ignorespaces {}}}{6}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(f)}{\ignorespaces {}}}{6}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(g)}{\ignorespaces {}}}{6}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(h)}{\ignorespaces {}}}{6}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(i)}{\ignorespaces {}}}{6}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(j)}{\ignorespaces {}}}{6}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(k)}{\ignorespaces {}}}{6}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(l)}{\ignorespaces {}}}{6}}
\newlabel{fig:experiment}{{8}{6}}
\newlabel{fig:experiment2:input}{{9a}{6}}
\newlabel{sub@fig:experiment2:input}{{(a)}{a}}
\newlabel{fig:experiment2:condition}{{9b}{6}}
\newlabel{sub@fig:experiment2:condition}{{(b)}{b}}
\newlabel{fig:experiment2:target}{{9c}{6}}
\newlabel{sub@fig:experiment2:target}{{(c)}{c}}
\newlabel{fig:experiment2:stn}{{9d}{6}}
\newlabel{sub@fig:experiment2:stn}{{(d)}{d}}
\newlabel{fig:experiment2:ours}{{9e}{6}}
\newlabel{sub@fig:experiment2:ours}{{(e)}{e}}
\newlabel{fig:experiment2:patchMatch}{{9f}{6}}
\newlabel{sub@fig:experiment2:patchMatch}{{(f)}{f}}
\newlabel{fig:experiment2:context-encoder}{{9g}{6}}
\newlabel{sub@fig:experiment2:context-encoder}{{(g)}{g}}
\newlabel{fig:experiment2:Image-to-Image}{{9h}{6}}
\newlabel{sub@fig:experiment2:Image-to-Image}{{(h)}{h}}
\newlabel{fig:experiment2:noShuffle}{{9i}{6}}
\newlabel{sub@fig:experiment2:noShuffle}{{(i)}{i}}
\newlabel{fig:experiment2:noSTN}{{9j}{6}}
\newlabel{sub@fig:experiment2:noSTN}{{(j)}{j}}
\newlabel{fig:experiment2:noGAN}{{9k}{6}}
\newlabel{sub@fig:experiment2:noGAN}{{(k)}{k}}
\newlabel{fig:experiment2:noL1}{{9l}{6}}
\newlabel{sub@fig:experiment2:noL1}{{(l)}{l}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Compare different image inpainting methods. (a) Input Left camera image. (b) Right camera image. (c) Target image. (d) The STN result. (e) Ours result. (f) Patch Match result. (g) Contexter-encoder result. (h) Image-to-Image result. (i) Ours(no shuffle) result. (j) Ours(no STN) result. (k) Ours(no GAN) result. (l) Ours(no L1) result.}}{6}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {}}}{6}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {}}}{6}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {}}}{6}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces {}}}{6}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(e)}{\ignorespaces {}}}{6}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(f)}{\ignorespaces {}}}{6}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(g)}{\ignorespaces {}}}{6}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(h)}{\ignorespaces {}}}{6}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(i)}{\ignorespaces {}}}{6}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(j)}{\ignorespaces {}}}{6}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(k)}{\ignorespaces {}}}{6}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(l)}{\ignorespaces {}}}{6}}
\newlabel{fig:experiment2}{{9}{6}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Image inpainting accuracy for different methods.}}{6}}
\newlabel{resultTable}{{1}{6}}
\@writefile{toc}{\contentsline {section}{References}{6}}
\bibcite{Hays2007::Scene}{11}
\bibcite{Hinton2006:s:Reducing}{12}
\bibcite{Bengio:Co:Learning}{13}
\bibcite{Vincent2008::Extracting}{14}
\bibcite{Goodfellow2014::Generative}{15}
\bibcite{Radford2016::Unsupervised}{16}
\bibcite{Pathak2016::Context}{17}
\bibcite{Li2017::Generative}{18}
\bibcite{Mirza2014:CS:Conditional}{19}
\bibcite{Isola2017::Image}{20}
\bibcite{Ronneberger2015::U}{21}
\bibcite{Li2016::Precomputed}{22}
\bibcite{Jaderberg2015::Spatial}{23}
\bibcite{Howard2017:apa:Mobilenets}{24}
\bibcite{Zhang2017:apa:Shufflenet}{25}
\bibcite{Ess2008::mobile}{26}
\bibcite{Chollet2017::Xception:}{27}
\bibcite{Xie2017::Aggregated}{28}
\bibcite{BoesenLindboLarsen2015:apa:Autoencoding}{29}
\bibcite{Kingma2014:apa:Adam:}{30}
\bibcite{IEEEhowto:kopka}{1}
\@writefile{toc}{\contentsline {section}{References}{7}}
