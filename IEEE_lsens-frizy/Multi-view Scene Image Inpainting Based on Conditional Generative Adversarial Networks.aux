\relax 
\citation{Efros1999::Texture,Lu2010::Novel}
\citation{Rane2002::Wavelet,Rane2003:IToIP:Structure}
\citation{Bertalmio2000::Image,Shih2005::Digital}
\citation{Geiger2012::Are}
\citation{Efros1999::Texture,Drori2003::Fragment,Wilczkowiak2005::Hole,Barnes2009:AToG:PatchMatch:}
\citation{Drori2003::Fragment}
\citation{Wilczkowiak2005::Hole}
\citation{Barnes2009:AToG:PatchMatch:}
\citation{Barnes2009:AToG:PatchMatch:}
\citation{Hays2007::Scene}
\citation{Hinton2006:s:Reducing,Bengio:Co:Learning}
\citation{Vincent2008::Extracting}
\citation{Goodfellow2014::Generative}
\citation{Radford2016::Unsupervised}
\citation{Pathak2016::Context}
\citation{Li2017::Generative}
\citation{Mirza2014:CS:Conditional}
\citation{Isola2017::Image}
\citation{Ronneberger2015::U}
\citation{Li2016::Precomputed}
\@writefile{toc}{\contentsline {section}{\numberline {I}Introduction}{1}}
\citation{Jaderberg2015::Spatial}
\citation{Howard2017:apa:Mobilenets}
\citation{Zhang2017:apa:Shufflenet}
\citation{Ess2008::mobile}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces A vehicle equipped with four cameras(Cam0\texttildelow Cam3).}}{2}}
\newlabel{fig:VehicleWithFourCameras}{{1}{2}}
\newlabel{fig:methods_compare:input}{{2a}{2}}
\newlabel{sub@fig:methods_compare:input}{{(a)}{a}}
\newlabel{fig:methods_compare:condition}{{2b}{2}}
\newlabel{sub@fig:methods_compare:condition}{{(b)}{b}}
\newlabel{fig:methods_compare:target}{{2c}{2}}
\newlabel{sub@fig:methods_compare:target}{{(c)}{c}}
\newlabel{fig:methods_compare:patchMatch}{{2d}{2}}
\newlabel{sub@fig:methods_compare:patchMatch}{{(d)}{d}}
\newlabel{fig:methods_compare:Image2Image}{{2e}{2}}
\newlabel{sub@fig:methods_compare:Image2Image}{{(e)}{e}}
\newlabel{fig:methods_compare:ourMethod}{{2f}{2}}
\newlabel{sub@fig:methods_compare:ourMethod}{{(f)}{f}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Qualitative illustration of the different image inpainting methods. (a) Given an image with a missing region captured by left camera. (b) Given the same scene image captured by right camera. (c) The target of the left image inpainting. (d) PatchMatch method result. (e) Image-to-Image method result. (f) Our method result. }}{2}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {}}}{2}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {}}}{2}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {}}}{2}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces {}}}{2}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(e)}{\ignorespaces {}}}{2}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(f)}{\ignorespaces {}}}{2}}
\newlabel{fig:methods_compare:introduction}{{2}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {II}Proposed Algorithm}{2}}
\citation{Hinton2006:s:Reducing,Bengio:Co:Learning,Vincent2008::Extracting}
\citation{Pathak2016::Context}
\citation{Isola2017::Image}
\citation{Jaderberg2015::Spatial}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces The network architecture of our method.}}{3}}
\newlabel{fig:networkStruct}{{3}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {II-A}}Encoder-decoder}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {II-B}}Spatial Transform}{3}}
\citation{Howard2017:apa:Mobilenets}
\citation{Chollet2017::Xception:}
\citation{Xie2017::Aggregated}
\citation{Zhang2017:apa:Shufflenet}
\citation{Goodfellow2014::Generative}
\citation{Mirza2014:CS:Conditional}
\citation{BoesenLindboLarsen2015:apa:Autoencoding,Pathak2016::Context,Isola2017::Image}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces The spatial transform networks used in our method.}}{4}}
\newlabel{fig:stn}{{4}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Bilinear interpolation schematic.}}{4}}
\newlabel{bilinearInterpolation}{{5}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {II-C}}Group Convolution and Channel Shuffle}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Multi-view scene image inpainting based on conditional generative adversarial networks method diagram.}}{4}}
\newlabel{fig:CGAN}{{6}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {II-D}}Conditional Generative Adversarial Networks}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {II-E}}Joint Loss Function}{4}}
\bibstyle{IEEEtran}
\bibdata{/mnt/hgfs/Downloads/refer-frizy/refer-frizy}
\bibcite{Efros1999::Texture}{1}
\bibcite{Lu2010::Novel}{2}
\bibcite{Rane2002::Wavelet}{3}
\bibcite{Rane2003:IToIP:Structure}{4}
\bibcite{Bertalmio2000::Image}{5}
\bibcite{Shih2005::Digital}{6}
\bibcite{Geiger2012::Are}{7}
\bibcite{Drori2003::Fragment}{8}
\bibcite{Wilczkowiak2005::Hole}{9}
\bibcite{Barnes2009:AToG:PatchMatch:}{10}
\bibcite{Hays2007::Scene}{11}
\bibcite{Hinton2006:s:Reducing}{12}
\bibcite{Bengio:Co:Learning}{13}
\bibcite{Vincent2008::Extracting}{14}
\bibcite{Goodfellow2014::Generative}{15}
\bibcite{Radford2016::Unsupervised}{16}
\bibcite{Pathak2016::Context}{17}
\bibcite{Li2017::Generative}{18}
\bibcite{Mirza2014:CS:Conditional}{19}
\bibcite{Isola2017::Image}{20}
\bibcite{Ronneberger2015::U}{21}
\bibcite{Li2016::Precomputed}{22}
\bibcite{Jaderberg2015::Spatial}{23}
\bibcite{Howard2017:apa:Mobilenets}{24}
\bibcite{Zhang2017:apa:Shufflenet}{25}
\bibcite{Ess2008::mobile}{26}
\bibcite{Chollet2017::Xception:}{27}
\bibcite{Xie2017::Aggregated}{28}
\bibcite{BoesenLindboLarsen2015:apa:Autoencoding}{29}
\bibcite{IEEEhowto:kopka}{1}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\unhbox \voidb@x \hbox {II-E}1}subsub}{5}}
\@writefile{toc}{\contentsline {section}{\numberline {III}Conclusion}{5}}
\@writefile{toc}{\contentsline {section}{Acknowledgment}{5}}
\@writefile{toc}{\contentsline {section}{References}{5}}
\@writefile{toc}{\contentsline {section}{References}{5}}
